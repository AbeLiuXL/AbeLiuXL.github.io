<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Xiaoliang Liu - Nanjing University - Personal Website</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #fff;
    }
    header {
       background-color: #DAE8FC;
       color: #000000;
       text-align: center;
       padding: 5px;
    }
    .container {
      margin: 20px auto;
      padding: 20px;
      background-color: #fff;
      width: 80%;
    }
    h1 {
      font-size: 24px;
    }
    h2 {
      font-size: 20px;
    }
    p {
      font-size: 16px;
      line-height: 1.6;
    }
    ul {
      list-style: none;
      padding: 0;
    }
    li {
      margin-bottom: 10px;
    }
    div[style="display: flex;"] {
  flex-wrap: wrap; /* 允许项目换行 */
}
.text {
  flex: 1; /* 使图片和文本区域灵活伸缩 */
}
  </style>
</head>
<body>
  <header>
    <h1>刘小亮（Xiaoliang Liu）</h1>
    <h2><a href="https://abeliuxl.github.io" style="color:rgb(0, 110, 175);text-decoration: none;">Main</a> | <a href="https://docs.qq.com/doc/p/574325869aa45ac6bbe9dc1f5b49e9630a873435" style="color:rgb(0, 110, 175);text-decoration: none;" target="_blank">Adversarial Attack</a> | <a href="https://docs.qq.com/doc/p/a3fa47e29419471627ef8e4b5385a322fee84f42" style="color:rgb(0, 110, 175);text-decoration: none;" target="_blank">Adversarial Robustness</a> </h2>
    <p><a href="index_cn.html">中文</a> | <a href="index.html">English</a></p>
  </header>
  <div class="container">
    <div style="display: flex;"> <img src="P3.jpeg" alt="Photo" width="150px" height="200px">
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <div class="text">
        <h2>Xiaoliang Liu</h2>
        <p><b>Email: xiaoliang_liu@smail.nju.edu.cn</b></p>
        <p><b>Homepage: <a href="https://abeliuxl.github.io">abeliuxl.github.io</a></b> </p>
        <p><a href="https://cs.nju.edu.cn/main.htm" style="color:rgb(0, 110, 175);text-decoration: none;" target="_blank">Department of Computer Science and Technology, Nanjing University</a>&nbsp;|&nbsp;<a href="https://keysoftlab.nju.edu.cn/main.htm" style="color:rgb(0, 110, 175);text-decoration: none;" target="_blank">National Key Laboratory for Novel Software Technology</a>&nbsp;|&nbsp;<a href="https://cs.nju.edu.cn/rinc/index.html" style="color:rgb(0, 110, 175);text-decoration: none;" target="_blank">Robotics Intelligence and Neural Computing (RINC) Research Group</a></p>
        </div>
    </div>
    <h2>Latest Updates</h2>
        <li>2024-05-23: Successfully passed the PhD dissertation defense.</li>
        <li>2024-03-31:Updated the paper link.</li>
    <hr>
    <hr>
    
    <h2>Education</h2>
    <p>2018.09 - Now Nanjing University, Ph.D. in Computer Science and Technology, Member of RINC Group, Supervisor: Prof. Furao Shen</p>
    <p>2016.09 - 2018.07 Nanjing University, M.S. in Computer Science and Technology, Member of RINC Group, Supervisor: Prof. Furao Shen</p>
    <p>2009.09 - 2014.07 Fujian University of Technology, B.S. in Communication Engineering</p>
    <hr>
    
    <h2>Research Interests</h2>
    <ul>
      <li>AI (Neural Network) Security</li>
      <li>Adversarial Learning</li>
      <li>Computer Vision</li>
      <li>Deep Neural Networks</li>
    </ul>
    <hr>
    <h2>Research Achievements</h2>
    <h4>Published Papers:</h4>
    <li>[1] <b>Xiaoliang Liu</b>, Furao Shen, Jian Zhao and Changhai Nie. AugRmixAT: A data processing and training method for improving multiple robustness and generalization performance [C]. IEEE International Conference on Multimedia and Expo (ICME). 2022: 1-6. [<a href="https://ieeexplore.ieee.org/document/9859665" target="_blank" style="color:rgb(0, 110, 175);">Paper</a>] (CCF-B，EI)
</li>
            <li>[2] <b>Xiaoliang Liu</b>, Furao Shen, Jian Zhao and Changhai Nie. Self-supervised learning of monocular 3D geometry understanding with two-and three-view geometric constraints[J]. The Visual Computer, 2024, 40(2): 1193-1204. [<a href="https://link.springer.com/article/10.1007/s00371-023-02840-y" target="_blank" style="color:rgb(0, 110, 175);">Paper</a>] (CCF-C，SCI，JCR-Q2)</li>
            <li>[3] <b>Xiaoliang Liu</b>, Furao Shen, Jian Zhao and Changhai Nie. EAP: An effective black-box impersonation adversarial patch attack method on face recognition in the physical world[J]. Neurocomputing, 2024: 127517. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231224002881" target="_blank" style="color:rgb(0, 110, 175);">Paper</a>] (CCF-C，SCI，JCR-Q2)</li>
            <li>[4] <b>Xiaoliang Liu</b>, Furao Shen, Jian Zhao and Changhai Nie. RandoMix: a mixed sample data augmentation method with multiple mixed modes[J]. Multimedia Tools and Applications, 2024: 1-17. [<a href="https://link.springer.com/article/10.1007/s11042-024-18868-8" target="_blank" style="color:rgb(0, 110, 175);">Paper</a>] (CCF-C，SCI，JCR-Q2)</li>

  <h4>Submitted Papers:</h4>
     <li>[5] <b>Xiaoliang Liu</b>, Furao Shen, Feng Han, Jian Zhao and Changhai Nie. NeRFTAP: Enhancing transferability of adversarial patches on face recognition using neural radiance fields[J]. arXiv preprint arXiv:2311.17332, 2023. [<a href="https://arxiv.org/abs/2311.17332" target="_blank" style="color:rgb(0, 110, 175);">Paper</a>] (CCF-B，SCI，Under Review)</li>
            <li>[6] <b>Xiaoliang Liu</b>, Furao Shen, Jian Zhao and Changhai Nie. RADAP: A robust and adaptive defense against diverse adversarial patches on face recognition[J]. arXiv preprint arXiv:2311.17339, 2023. [<a href="https://arxiv.org/abs/2311.17339" target="_blank" style="color:rgb(0, 110, 175);">Paper</a>] (CCF-B，SCI，Under Review)</li>

  <h4>Patents:</h4>
    <li>[7] Furao Shen, Kepan Gao, <b>Xiaoliang Liu</b>, et al. A method for indoor localization by fusing UWB and LiDAR: 202011520518[P] [2024-02-28].</li>

  <h4>Book Chapters:</h4>
    <li>[8] Furao Shen. Self-Organizing Incremental Learning Neural Networks[M]. Electronic Industry Press, September 2023. (Chapter 1: Mathematical Foundations)</li>
  <hr>
  <h2>Awards</h2>
        <li>2022.08 - 2023.03, the First Greater Bay Area (Huangpu) International Algorithm Competition, Adversarial Robustness Defense Algorithm for Deep Learning Models, Finalist Prize. (Individual Participation)</li>
<hr>
    <h2>Research Projects</h2>
    <li>State Grid Corporation of China Headquarters Science and Technology Project, Research and Application of Substation HD Video and Robot Joint Inspection Technology Based on Multi-Dimensional Image Intelligent Matching and Recognition, Project Number: 520950200009. (Participant)</li>

    <li>Ministry of Science and Technology Major Project - the STI 2030-Major Projects of China, Efficient Learning Mechanism of Spiking Networks Based on Neural Plasticity and Brain-Inspired Intelligence System, Grant Nos: 2021ZD0201300. (Participant)</li>

    <li>National Natural Science Foundation of China General Program, Research on Novel Neural Networks for Incremental Unsupervised Learning, Grant Nos: 62276127. (Participant)</li>
<hr>
  <h2>Research Services</h2>
  <li> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT, Peer Reviewer)</li>
  <hr>
  
  <h2>Contact Information</h2>
  <ul>
    <li>Email: xiaoliang_liu@smail.nju.edu.cn</li>
    <li>Address: Room 426, Building of Computer Science and Technology, Xianlin Campus of Nanjing University</li>
    <li>ORCiD:  <a
    id="cy-effective-orcid-url"
    class="underline"
     href="https://orcid.org/0000-0002-3776-6929"
     target="orcid.widget"
     rel="me noopener noreferrer"
     style="vertical-align: top">
     <img
        src="https://orcid.org/sites/default/files/images/orcid_16x16.png"
        style="width: 1em; margin-inline-start: 0.5em"
        alt="ORCID iD icon"/>
      https://orcid.org/0000-0002-3776-6929
    </a></li>
    <li>Web of Science: <a href="https://www.webofscience.com/wos/author/record/KFQ-9516-2024" target="_blank">KFQ-9516-2024</a></li>
    <li>Google Scholar: <a href="https://scholar.google.com/citations?hl=zh-CN&user=Eg6rWc8AAAAJ" target="_blank">Xiaoliang Liu</a></li>
  </ul>
  <hr>
  <hr>
  </div>

<footer style="text-align: center;">
<p>Copyright &copy; 2023-2024 Xiaoliang Liu</p>
</footer>
</body>
</html>

